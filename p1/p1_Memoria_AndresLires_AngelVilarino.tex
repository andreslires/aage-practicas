% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\begin{document}
%
\title{AAGE - Práctica 1 (MLlib): }
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Andrés Lires Saborido\inst{1}\and
Ángel Vilariño García\inst{2}}
%
\authorrunning{A. Lires \and Á. Vilariño}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{ Universidade da Coruña, \email{andres.lires@udc.es} 
\and Universidade da Coruña, \email{angel.vilarino.garcia@udc.es}
}

%
\maketitle              % typeset the header of the contribution
%

\begin{abstract}
En este proyecto se presenta un problema de clasificación y predicción de retrasos de vuelos durante el año 2019, 
haciendo uso de un conjunto de datos extraído de Kaggle, \textit{2019 Airline Delays w/Weather and Airport Detail}~\cite{url_kaggle}. 
El objetivo es desarrollar un modelo de clasificación binaria capaz de estimar si un vuelo se retrasará a partir de una serie de 
variables operativas y meteorológicas conocidas antes de la salida. Dado el gran volumen y la heterogeneidad de los datos, se emplea 
Apache Spark MLlib~\cite{url_spark} para realizar todas las fases del trabajo: preprocesamiento de datos y el entrenamiento de 
diferentes modelos de aprendizaje automático a gran escala. Se comparan distintos algoritmos, así como diferentes modelos gracias 
a combinaciones de características o hiperparámetros para tratar de obtener el mejor modelo predictivo.


\keywords{Big Data \and Machine Learning \and Apache Spark \and MLlib \and Binary Classification 
\and Prediction \and Flight Delays \and Airports \and Weather \and Data Analysis \and Data Science}
\end{abstract}


\section{Introducción}
\subsection{Dataset}
El conjunto de datos elegido es \textit{2019 Airline Delays w/Weather and Airport Detail}~\cite{url_kaggle}, 
disponible en Kaggle, plataforma gratuita. Contiene más de 6 millones de vuelos realizados en 
Estados Unidos durante el año 2019, con información sobre aerolíneas, el vuelo, condiciones del 
aeropuerto, de la aeronave y meteorológicas.

El conjunto presenta 26 variables, explicadas con mayor detalle en la Tabla~\ref{tab:variables}. 
Las diferentes características, tanto categóricas como numéricas, pueden ser utilizadas de 
manera conjunta para analizar las condiciones operativas o meteorológicas que llevan al retraso 
de vuelos.


\begin{table}[h!]
\centering
\caption{Resumen de las variables del dataset}
\label{tab:variables}
\begin{tabular}{|l|c|l|}
\hline
\textbf{Variable} & \textbf{Tipo} & \textbf{Descripción} \\ \hline
MONTH & Numérica & Mes del vuelo \\ \hline
DAY\_OF\_WEEK & Numérica & Día de la semana (1 = Lunes) \\ \hline
DEP\_DEL15 & Binaria & Salida retrasada 15 min o más (1 = Retrasado) \\ \hline
DEP\_TIME\_BLK & Categórica & Bloque horario de salida \\ \hline
DISTANCE\_GROUP & Numérica & Grupo de distancia del vuelo \\ \hline
SEGMENT\_NUMBER & Numérica & Vuelos previos del avión hoy \\ \hline
CONCURRENT\_FLIGHTS & Numérica & Vuelos simultáneos en el mismo bloque \\ \hline
NUMBER\_OF\_SEATS & Numérica & Número de asientos \\ \hline
CARRIER\_NAME & Categórica & Aerolínea \\ \hline
AIRPORT\_FLIGHTS\_MONTH & Numérica & Promedio de vuelos aeropuerto/mes \\ \hline
AIRLINE\_FLIGHTS\_MONTH & Numérica & Promedio de vuelos aerolínea/mes \\ \hline
AIRLINE\_AIRPORT\_FLIGHTS\_MONTH & Numérica & Promedio de vuelos aerolínea+ aeropuerto/mes \\ \hline
AVG\_MONTHLY\_PASS\_AIRPORT & Numérica & Promedio pasajeros aeropuerto/mes \\ \hline
AVG\_MONTHLY\_PASS\_AIRLINE & Numérica & Promedio pasajeros aerolínea/mes \\ \hline
FLT\_ATTENDANTS\_PER\_PASS & Numérica & Tripulantes por pasajero \\ \hline
GROUND\_SERV\_PER\_PASS & Numérica & Personal tierra por pasajero \\ \hline
PLANE\_AGE & Numérica & Edad del avión \\ \hline
DEPARTING\_AIRPORT & Categórica & Aeropuerto de salida \\ \hline
LATITUDE & Numérica & Latitud aeropuerto \\ \hline
LONGITUDE & Numérica & Longitud aeropuerto \\ \hline
PREVIOUS\_AIRPORT & Categórica & Aeropuerto previo \\ \hline
PRCP & Numérica & Precipitación (pulgadas) \\ \hline
SNOW & Numérica & Nieve caída (pulgadas) \\ \hline
SNWD & Numérica & Profundidad de nieve (pulgadas) \\ \hline
TMAX & Numérica & Temp. máxima (°F) \\ \hline
AWND & Numérica & Velocidad máxima viento (m/s) \\ \hline
\end{tabular}
\end{table}

El número de filas del dataset justifica el uso de Apache Spark, motor de procesamiento 
distribuido, para el entrenamiento de modelos de aprendizaje automático a gran escala.

\subsection{Definición del problema}
El objetivo del proyecto es predecir si un vuelo será retrasado o no antes de su salida, 
utilizando la información disponible en el dataset.

Se trata de un problema de clasificación binaria supervisada, donde la variable objetivo es 
DEP\_DEL15 (valor 1 si el vuelo salió con más de 15 minutos de retraso, 0 en otro caso). 
Entre las variables que nos ayudarán a lograr la predicción se encuentran características 
del vuelo (aerolínea, origen, destino, mes, día de la semana) y condiciones meteorológicas 
en el aeropuerto de origen.

Para resolver el problema se emplearán distintos modelos de Spark MLlib, haciendo uso de 
diferentes algoritmos, características o hiperparámetros de manera justificada. Estos modelos se evaluarán de 
acuerdo a métricas adecuadas al problema.


\section{Análisis exploratorio de datos (EDA)}

En esta sección se llevó a cabo un análisis exploratorio de los datos para comprender mejor las características
 del dataset y la relación entre las variables. Se utilizaron técnicas de visualización y estadísticas descriptivas
 para identificar patrones, tendencias y posibles problemas en los datos.

El análisis completo se puede encontrar en el cuaderno de Jupyter adjunto \textit{p1_AndresLires_AngelVilarino.ipynb}, aquí se recogen 
las conclusiones más relevantes obtenidas tras el EDA.

% Hacemos una lista de conclusiones del EDA
\begin{itemize}
    \item El dataset contiene más de 6 millones de registros, lo que justifica el uso de Apache Spark para su procesamiento.
    \item La variable objetivo (DEP\_DEL15) está desbalanceada, con aproximadamente un 20\% de vuelos retrasados.
    \item Ninguna variable presenta valores nulos.
    \item Distribución de la variable objetivo por mes y aerolínea en Figuras~\ref{fig:delays_by_month} y ~\ref{fig:delays_by_carrier}.
    \item La variables meteorológicas (PRCP, SNOW, SNWD, TMAX, AWND) parecen tener una influencia 
    significativa en los retrasos a la vista de la Tabla~\ref{tab:weather_stats}.

\end{itemize}

% Añadimos la tabla
\begin{table}[h!]
\centering
\caption{Promedios de variables meteorológicas según si el vuelo tuvo retraso}
\begin{tabular}{c|ccccc}
\hline
\textbf{Retraso} & \textbf{avg(PRCP)} & \textbf{avg(SNOW)} & \textbf{avg(SNWD)} & \textbf{avg(TMAX)} & \textbf{avg(AWND)} \\
\hline
1 & 0.1608 & 0.0645 & 0.1309 & 71.1289 & 8.7219 \\
0 & 0.0904 & 0.0239 & 0.0823 & 71.5477 & 8.2526 \\
\hline
\end{tabular}
\label{tab:weather_stats}
\end{table}

    
% Añadimos las figuras
\begin{figure}[h!]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/delays_by_month.png}
        \caption{Distribución de vuelos retrasados por mes y semana (Gráfica hecha en PowerBI)}
        \label{fig:delays_by_month}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/delays_by_carrier.png}
        \caption{Distribución de vuelos retrasados por aerolínea}
        \label{fig:delays_by_carrier}
    \end{minipage}
\end{figure}



\section{Preprocesado de datos}

En un primer lugar, se ha realizado un under-sampling del dataset para balancear la variable objetivo,
reduciendo el número de registros con valor 0 en DEP\_DEL15 para igualarlo al número de registros con valor 1.
De esta forma conseguimos equilibrar las clases y al mismo tiempo reducir el tamaño del dataset, lo que acelera el
entrenamiento de los modelos.

Se ha realizado un preprocesado general inicial (StringIndexer, OneHotEncoder, VectorAssembler)
pero durante la experimentación se han realizado ajustes específicos para cada modelo, que se explicarán más adelante.

\section{Experimentación}

La fase de experimentación fue muy extensa, probando diferentes combinaciones de características, modelos,
métodos de muestreo y métricas de evaluación. A continuación se describen los aspectos más relevantes.

En todos los casos se ha realizado un \textit{train-test split} del 80\%-20\% para evaluar los modelos.

\subsection{Muestreo}

Durante la experimentación se probaron diferentes técnicas de reducción de filas o subconjuntos de datos:
\begin{itemize}
    \item \textit{Under-sampling}: Como se ha mencionado anteriormente, se realizó un under-sampling para balancear la variable objetivo.
    \item \textit{Stratified Sampling}: Se probó a realizar un muestreo estratificado para mantener la proporción original de clases en el conjunto de datos. 
\end{itemize}

\subsection{Selección de características}

A lo largo de la experimentación se entrenaron modelos con diferentes subconjuntos de características. 
Las selecciones consideradas son las siguientes:

\begin{enumerate}
    \item Todas las características.
    \item Solo las características numéricas: De esta forma se elimina el coste computacional asociado a las variables categóricas, 
    que se transforman en múltiples columnas tras aplicar el \textit{OneHotEncoder}.
    \item Características meteorológicas y categóricas: Estas columnas parecen, según el análisis exploratorio, estar relacionadas con la variable objetivo.
    \item Características definidas por un algoritmo de selección (\textit{UnivariateFeatureSelector}).
\end{enumerate}

\subsection{Métricas de evaluación}
Dado que se trata de un problema de clasificación binaria, se han utilizado las siguientes métricas para evaluar los modelos:
\begin{itemize}
    \item \textit{Accuracy}: Proporción de predicciones correctas sobre el total de predicciones.
    \item \textit{Precision}: Proporción de verdaderos positivos sobre el total de positivos predichos.
    \item \textit{Recall}: Proporción de verdaderos positivos sobre el total de positivos reales.
    \item \textit{F1-Score}: Media armónica entre \textit{Precision} y \textit{Recall}, útil cuando las clases están desbalanceadas.
\end{itemize}

Según el conjunto de datos que se utilice en el entrenamiento concreto (balanceado o desbalanceado) se dará más 
importancia a unas métricas u otras. En el caso del dataset desbalancado, no podemos fiarnos del \textit{Accuracy}
(ya que un modelo que siempre prediga la clase mayoritaria obtendría un buen resultado),
por lo que se dará más importancia al \textit{F1-Score}.

\subsection{Modelos probados}
\begin{itemize}
    \item Regresión logística (Logistic Regression - LR)
    \item Máquinas de vectores de soporte (Support Vector Machines - SVM)
    \item Árboles de decisión (Decision Trees - DT)
    \item Bosques aleatorios (Random Forest - RF)
    \item Gradient Boosted Trees (GBT)
    \item Redes neuronales (Multilayer Perceptron - MLP)
    \item Naive Bayes (NB)
\end{itemize}

\section{Desarrollo de la experimentación}
El desarrollo completo de la experimentación se encuentra en el cuaderno de Jupyter adjunto \textit{p1_AndresLires_AngelVilarino.ipynb}. Aquí 
se resumen los aspectos más relevantes y las conclusiones obtenidas en cada fase.

Primero se prueba con el dataset balanceado, entrenando los modelos LR, SVM, DT y RF
(modelos clásicos para clasificación binaria) con todas las características y sus hiperparámetros por defecto. 
Posteriormente, como los resultados no son satisfactorios, se incluye el 
modelo de Gradient Boosted Trees(GBT)~\cite{url_gbt}, técnica más novedosa, que suele ofrecer buenos 
resultados en problemas de clasificación binaria. Estos 5 modelos se entrenan con parámetros 
por defecto sobre los 4 subconjuntos de características definidos anteriormente. 

El GBT, sobre todas las características o sobre meteorológicas + categóricas, resulta 
ser el mejor en términos de accuracy (64\%), métrica fiable al tratarse de un dataset balanceado.

A continuación, ya que LR y SVM son sensibles a la escala se prueban a entrenar de nuevo aplicando RobustScaler, resistente a 
outliers o distribuciones sesgadas (presentes en nuestro dataset)~\cite{url_robustscaler}.

Los resultados siguen sin ser buenos por lo que se decide probar con un nuevo submuestreo, que mantiene 
la distribución inicial del dataset desbalanceado\footnote{Por motivos de rendimiento este subconjunto es de menor tamaño 
($\approx$ 1 millón de filas en total)}. En este caso, como se citó anteriormente, la métrica más relevante es el F1-Score.
Se entrenan de nuevo los modelos GBT, LR, SVM, DT y RF, esta vez solamente sobre todas 
las características y sigue sin haber mejoras significativas. 
El GBT es en este caso también el mejor modelo, con un F1-Score del 68\%.

Es en este momento cuando se decide probar nuevos modelos: MLP y Naive Bayes. 
El MLP ofrece un F1-Score del 73.1\%, superando al GBT, mientras que el Naive Bayes
no consigue mejorar los resultados anteriores.




\section{Modelo final}

\section{Conclusiones}







%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}

\bibitem{url_kaggle}
Página de Kaggle del dataset, 
\url{https://www.kaggle.com/datasets/threnjen/2019-airline-delays-and-cancellations/data}, 
descargado el 08/10/2025.

\bibitem{url_spark}
Página sobre MLlib en la web de Spark, 
\url{https://spark.apache.org/mllib/}

\bibitem{url_gbt}
\textit{Comparison of 14 different families of classification algorithms on 115 binary datasets}. 
arXiv preprint arXiv:1606.00930 (2016),
\url{https://arxiv.org/abs/1606.00930}

\bibitem{url_robustscaler}
Comparación de diferentes métodos de escalado,
\url{https://machinelearningmastery.com/minmax-vs-standard-vs-robust-scaler-which-one-wins-for-skewed-data/}


\end{thebibliography}

\end{document}
